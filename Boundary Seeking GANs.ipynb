{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Boundary Seeking GANs\n",
    "This paper presents another (slightly different) way  of training GANs. This approach can also be used to train GANs with discrete output.\n",
    "\n",
    "In short the objective can be described as training G to produce samples that lie on the decision boundary of D.\n",
    "\n",
    "It is also very easy to implement (TODO: in the continuous case only?).\n",
    "\n",
    "## Background\n",
    "In GANs we have the following objective\n",
    "$$\\min_G \\max_D \\mathbb{E}_{p_{data}(x)} \\left[ log\\ D(x) \\right] + \\mathbb{E}_{p_z(z)} \\left[ log (1 - D(G(z))) \\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
