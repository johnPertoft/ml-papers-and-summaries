{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Generative Adversarial Networks\n",
    "\n",
    "## Basics\n",
    "This paper introduces a new framework for fitting generative models. The goal in these cases is to try to find a model that is close to some data distribution that we want to generate more examples from. The traning set are samples from this distribution.\n",
    "\n",
    "In essence this is done by training two models at the same time in an adversarial process. One is a generative model $G$ that tries to capture the data distribution and one is a discriminative model $D$ that tries to distinguish whether a sample came from the training data or from $G$, i.e. output a high probability for $x \\sim p_{data}(x)$ (training data) and low probability for $x \\sim p_G(x)$. \n",
    "\n",
    "The training goal of $G$, that will steer the direction of weight updates, is to generate samples that will fool the $D$ model. Or informally, $G$ wants to generate samples $x$ that $D$ gives a high probability for. This can be expressed as the following mini max game.\n",
    "\n",
    "$$\\min_G \\max_D \\mathbb{E}_{p_{data}(x)} \\left[ log\\ D(x) \\right] + \\mathbb{E}_{p_z(z)} \\left[ log (1 - D(G(z))) \\right]$$\n",
    "\n",
    "A solution to this equation exists where $G$ perfectly models the training data distribution and $D$ outputs $\\frac{1}{2}$ for all $x$ generated from $G$.\n",
    "\n",
    "A good conceptual model of this is pointed out by the authors where the generative model $G$ is a money counter feiter and the discriminative model $D$ is the police who tries to see which are real and which are fake bills. The competition between them forces both to become better. This drives the generative model towards the goal of modeling the actual data distribution.\n",
    "\n",
    "### Problems with other generative models\n",
    "Before this, getting good results with deep generative models has been difficult and the success has been smaller than for deep discriminative models (e.g. input an image, get a label out). This is mostly because of the difficulties with intractable computations for posterior distributions. This is usually solved with sampling techniques like *markov chain monte carlo* (MCMC) or other approximation techniques like *variational inference* which both have pros and cons. But this paper at least introduces an alternative when it comes to generative models.\n",
    "\n",
    "### Specifics of GAN\n",
    "The adversarial idea works for all (?) generative models. But the work in this paper is with neural networks which forms the special case of *adversarial nets* which can be trained using backpropagation and dropout.\n",
    "\n",
    "For adversarial nets we first define a prior $p_z(z)$ on input variables $z$ to $G$ which are just noise.\n",
    "\n",
    "The network then represents a mapping $G(z, \\theta_g)$ to the data space of things we want to generate. $G(z, \\theta_g)$ is differentiable which makes backpropagation possible. $\\theta_g$ are the parameters of this network.\n",
    "\n",
    "We also have a second neural network $D(x, \\theta_d)$ which is a mapping from data space to a scalar value that represents the probability that $x$ came from the actual data distribution rather than from $p_g$ (from $G$). $D(x)$ should be high for samples $x$ which are from the training data and low otherwise.\n",
    "\n",
    "$D$ is trained to maximimize the probability assigning the correct label to both samples drawn from training data and samples drawn from $G$. At the same time, $G$ is trained to minimize $log(1 - D(G(z)))$, which is the same as saying that we are training $G$ to create samples $x$ that $D$ says are real samples which thus minimizes the expression.\n",
    "\n",
    "This is expressed as the following min max equation and is what the loss functions when implementing this are based on. In practice this is optimized iteratively as a sort of balancing equilibrium.\n",
    "\n",
    "$$\\min_G \\max_D \\mathbb{E}_{p_{data}(x)} \\left[ log\\ D(x) \\right] + \\mathbb{E}_{p_z(z)} \\left[ log (1 - D(G(z))) \\right]$$\n",
    "\n",
    "#### Training in practice\n",
    "The training is done by iteratively updating the weights of both networks.\n",
    "\n",
    "If we were to have a nested loop for updating $G$ in the outer and $D$ in the inner, it would result in overfitting.\n",
    "\n",
    "Instead training is done by $k$ steps of updates to $D$ followed by 1 step of update to $G$. In this way, $D$ is kept almost optimal for its task while $G$ slowly becomes better at generating samples close to the data distribution. When one model is updated the other is kept fixed.\n",
    "\n",
    "In practice, the gradient from the min max equation might not work well for learning. This is because when $G$ initially is very bad, $log (1 - D(G(z))$ saturates. Thus, it can sometimes be a good idea to initially have $G$ be updated by instead *maximizing* $log (D(G(z)))$ which gives stronger gradients initially.\n",
    "\n",
    "The following image show the incremental learnings of both nets. Here the black dotted line is the data distribution, the green line is the generated distribution of $G$, and the blue dashed line is the output of $D$. Here $z$'s are sampled from the bottom horizontal line and then mapped via $G$ to $x$ which are distributed according to the green line.\n",
    "\n",
    "In the fourth plot, $G$ matches the data distribution perfectly and thus $D$ can't distinguish between them and says it's 50/50.\n",
    "\n",
    "<img src=\"figs/GAN/gan-training.png\" width=\"80%\" height=\"80%\">\n",
    "\n",
    "\n",
    "**Pseudo code**\n",
    "```\n",
    "while not done:\n",
    "    iterate k times:\n",
    "        sample m noise inputs z_1,...,z_m from noise prior\n",
    "        sample m data examples x_1,...,x_m from data distribution (training data)\n",
    "        update discriminator D by ascending gradient of Eq1\n",
    "    \n",
    "    sample m noise inputs z_1,...,z_m from noise prior\n",
    "    update generator G by descending gradient of Eq2 (or using the in practice trick for early iterations)  \n",
    "```\n",
    "\n",
    "where Eq1 and Eq2 are defined below \n",
    "\n",
    "$$Eq1:\\, \\nabla_{\\theta_d} \\frac{1}{m} \\sum^m_{i=1} log(D(x_i)) + log(1 - D(G(z_i))) \\quad Eq2:\\, \\nabla_{\\theta_g} \\frac{1}{m} \\sum^m_{i=1} log(1 - D(G(z_i)))$$\n",
    "\n",
    "\n",
    "#### The noise prior input p(z)\n",
    "The paper doesn't say what kind of distribution they use in their experiments, but from what I've read elsewhere it seems to often be a normal or uniform distribution.\n",
    "\n",
    "#### Theory\n",
    "TODO: explain and summarize proofs\n",
    "\n",
    "TODO: game theory - nash equilibrium\n",
    "\n",
    "\n",
    "### Experiments\n",
    "The image show generated examples where $G$ has been trained on different datasets. The closest training image is shown in the right column.\n",
    "<img src=\"figs/GAN/gan-experiments.png\" width=\"80%\" height=\"80%\">\n",
    "\n",
    "\n",
    "### Problems\n",
    "Can be difficult to train, because $G$ and $D$ have to be kept in sync since they basically teach each other. If one is too weak, the other will not be able to learn what it should.\n",
    "\n",
    "This can cause a degenerate case where $G$ only generates a single example from many different $z$ and which is badly classified by $D$. This also shows that $G$ doesn't necessarily converge to the data distribution. *Helvetica scenario*\n",
    "\n",
    "\n",
    "## Discussion and Thoughts\n",
    "This adversarial training technique is nice because it can be applied in many different models. See *Adversarial Autoencoders* for example.\n",
    "\n",
    "TODO: read nips 2016 tutorial on GAN for more tips and tricks, https://arxiv.org/pdf/1701.00160v1.pdf\n",
    "\n",
    "The adversarial technique seems to have become popular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
