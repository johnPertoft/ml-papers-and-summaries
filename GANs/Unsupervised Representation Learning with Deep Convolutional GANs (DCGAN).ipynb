{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Unsupervised Representation Learning with Deep Convolutional GANs\n",
    "This paper is mainly concerned with learning feature representations. They do this by using the GAN framework while also using CNNs for the generator and discriminator which later has become the standard in most GAN variants.\n",
    "\n",
    "Contributions\n",
    "* A more stable architecture using convolutions\n",
    "* Good way to learn image representations (unsupervised) with some representation arithmetic capabilities\n",
    "\n",
    "## Model architecture guidelines\n",
    "* Replace deterministic spatial pooling functions (like maxpool) with strided convolutions in discriminator and fractional-strided convolutions (transposed convolution or \"deconvolutions\") in generator.\n",
    "* Eliminate fully connected layers. \n",
    "    * Can use global average pooling.\n",
    "    * Often just flatten last conv layer into 1 sigmoid output though.\n",
    "* Batch normalization in both discriminator and generator gives more stability in training.\n",
    "    * No batch norm on generator output layer.\n",
    "    * No batch norm on discriminator input layer.\n",
    "* ReLU activations in all layers of generator except output\n",
    "* Leaky ReLU activations in all layers of discriminator (I guess except output?).\n",
    "\n",
    "## Experiments\n",
    "They train DCGANs on\n",
    "* LSUN\n",
    "* Imagenet-1K\n",
    "* A new face dataset\n",
    "\n",
    "With the following settings\n",
    "* Minibatch size 128\n",
    "* Weight initialization with $\\mathcal{N}(0, 0.02^2)$\n",
    "* Leaky ReLU leak slope = 0.2\n",
    "* Adam optimizer with learning rate 0.0002, $\\beta_1=0.5$\n",
    "\n",
    "### Classification using learnt representations\n",
    "They evaluate the quality of the representations that the DCGANs yield by using it as a feature extractor on images in a labeled datasets and then train different linear models on the features extracted.\n",
    "\n",
    "They train a DCGAN on Imagenet-1K. The extracted representation of each image is computed by\n",
    "1. Taking the output of each convolutional layer of the discriminator.\n",
    "2. Maxpooling them into 4x4 (at each filter). \n",
    "3. Flatten these and concatenated to form a 28672 dimensional vector.\n",
    "\n",
    "They fit a $l_2$-SVM classifier on these representations which gives pretty good results when testing on CIFAR-10.\n",
    "\n",
    "### Investing the internals of the networks\n",
    "They state that\n",
    "* Nearest neighbor search on training set in pixel or feature space is often bad because it can be fooled by small image transforms.\n",
    "* No log likelihood (I guess parzen window estimates?) as it's a bad visual quality metric.\n",
    "\n",
    "#### Walking the latent space\n",
    "* Sharp transitions in latent space usually means that the model just memorizes data.\n",
    "* If walking in latent space results in semantic changes like objects being added, the model has probably learnt relevant representations.\n",
    "\n",
    "#### Visualizing discriminator features\n",
    "Using guided backpropagation they show that the discriminator learns features that activate for semantically interesting parts of a bedroom (LSUN dataset) like windows and beds.\n",
    "\n",
    "#### Manipulating generator representation\n",
    "* They say that the quality of samples suggest that the generator learns specific object representations (beds/windows/lamps/doors etc).\n",
    "* They try to remove windows from being generated in an experiment.\n",
    "    * Manually draw bounding boxes on windows in 150 samples.\n",
    "    * On second highest conv layer features, do logistic regression to predict if feature activation was on window or not to learn which features correspond to drawing windows.\n",
    "    * They drop the features corresponding to drawing windows from all spatial locations and then continue generating without them to generate samples without windows. Working ok:ish.\n",
    "    \n",
    "#### Vector arithmetic\n",
    "They test if doing vector arithmetic on the $Z$ representation can do anything useful.\n",
    "\n",
    "* Single samples not working well.\n",
    "* Averaging Z vectors for multiple examples worked better.\n",
    "* Example: *smiling woman* - *neutral woman* + *neutral man* = *smiling man* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
