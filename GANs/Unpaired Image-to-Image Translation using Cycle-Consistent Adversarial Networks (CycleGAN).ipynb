{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks\n",
    "* This paper presents an approach to image translation, i.e. translating and image in one \"domain\" to its corresponding image in another domain.\n",
    "\n",
    "* Note that this approach does not require training data to consist of image pairs but instead just trains on two bags of images that we want to be able to translate between. The main idea is to use an adversarial loss to accomplish this.\n",
    "\n",
    "* Image domains are basically just different distributions over the image space, e.g. nature pictures with and without snow. In the paper they are denoted by $X$ and $Y$. Not sure how to define the \"translation\" mathematically, conceptually it's pretty straight forward though. I think the assumption though, is that for two images that are each other's translation there exists some common latent factor or as the authors say, \"two different renderings of the the same underlying scene\".\n",
    "\n",
    "## The Parts of Cycle GAN\n",
    "* One generator $G: X \\rightarrow Y$\n",
    "* One generator $F: Y \\rightarrow X$\n",
    "* One discriminator $D_X: X \\rightarrow \\text{determine whether real or fake/translated X}$\n",
    "* One discriminator $D_Y: Y \\rightarrow \\text{determine whether real or fake/translated Y}$\n",
    "\n",
    "## Training\n",
    "### Generators\n",
    "$G$ and $F$ are trained by a optimizing for a loss defined in multiple parts.\n",
    "* First the adversarial loss, $G(x) \\rightarrow \\hat{y}$ is trained to look like $y \\sim Y$.\n",
    "    * No guarantee of meaningful translation of individual $x$ and $y$, only at a macro level.\n",
    "* Second, the cycle consistency loss. Translations should be cycle consistent, i.e. be translatable back and forth. Or in other words $G$ and $F$ should be each other's inverses and be bijections (each element in each set is mapped to one other element in the other set and vice versa).\n",
    "    * Cycle consistency loss: $G$ and $F$ is also trained to $F(G(x)) \\approx x$ and $G(F(y)) \\approx y$ by $l_1$ distance.\n",
    "* The total loss is $\\mathcal{L}_{GAN} + \\lambda \\mathcal{L}_{cyclic}$\n",
    "\n",
    "### Discriminators\n",
    "Discriminators $D_X$ and $D_Y$ are only trained by the adversarial loss, that is they want to classify real samples as real and translated samples as fake.\n",
    "* In practice they use least squares loss instead of normal negative log likelihhood loss in the adversarial loss parts.\n",
    "* They also update the discriminators based on a history of generated/translated images instead of just the ones from the latest version of the generative networks. They that they use the 50 previously generated images but I suppose this should depend on batch size? TODO: Read implementation\n",
    "\n",
    "## Architectures\n",
    "### Generators\n",
    "* Adapted from the neural style paper.\n",
    "* According to paper:\n",
    "    * 2 stride-2 convolution layers.\n",
    "    * 6 or 9 (depending on image size) residual blocks.\n",
    "    * 2 fractionally strided convolutions with stride 1/2\n",
    "    * They use instance normalization.\n",
    "\n",
    "### Discriminators\n",
    "* Taken from PatchGAN paper\n",
    "    * Not a single scalar output but instead one output per image patch determined by the convolutions.\n",
    "    * This means fewer parameters.\n",
    "    * They are then combined for the final discriminator output.\n",
    "\n",
    "## TODO:\n",
    "* They point out that this setup is similar to that of adversarial autoencoders, in that two of these are trained jointly where the target distributions are the translations of each respective domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
