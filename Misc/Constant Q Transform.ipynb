{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Note: this is just some random notes about the papers about the *constant q transform* I made while trying to understand it. Don't really think I have the right background for it anyway, so it's a mess.\n",
    "\n",
    "\n",
    "# Constant Q Transform\n",
    "\n",
    "## Fourier Transform\n",
    "In essence, the fourier transform\n",
    "\n",
    "A sinusoid is a sum of sin and cos (at least here?)\n",
    "\n",
    "The fourier transform gives one complex coefficient per frequency. The real part of the complex coefficient $c$ is the correlation with the cosine function of the sinusoid and the imaginary is the correlation with the sine function. By working with complex coefficients, we just have to consider one integral.\n",
    "\n",
    "A weakness of fft is that they consider the whole signal. If the signal changes abruptly, it will not work so well. This is why things like stft are used, and now cqt also. Also wavelets. Compact support etc.\n",
    "\n",
    "### How dft works in a computer\n",
    "You have some audio sample of some given time duration and sample frequency, called x.\n",
    "\n",
    "Then you basically, synthesize sinusoids for all possible frequencies in this signal x. The lowest possible frequency is the one which just has one wavelength (true?) for the entire duration of x, and the highest possible frequency is the one which has one wavelength for every two samples of x. For each of these synthesized sinusoids, we take the dot product with the signal x. (This is disregarding phase shifts I think?) The dot product tells how much of the current frequency is in the real signal I guess?\n",
    "\n",
    "Since the phase of frequencies might not match, the complex numbers come into play. The results of the dot product are complex numbers where the real part corresponds to the synthesized signal with 0 degree phase shift and the complex to the one with 90 degree phase shift but both with the same frequency. The magnitude of the resulting complex number is the contribution of this frequency regardless of any phase differences in what we are analyzing. (Not entirely sure of all this, like what if all possible phase shifts of a certain frequency are present?)\n",
    "\n",
    "Then this can all be viewed as a matrix multiplication which is also why the dft/fft can be viewed as a linear operator. This can then be computed with lower time complexity than normal matrix multiplication through other tricks (FFT divide and conquer).\n",
    "\n",
    "When doing this for real audio (eg to get a spectrogram of a song), you usually split the signal into frames and apply the fft to each one. When splitting into frames, frequencies that arent actually there are introduced since we might cut in the middle of a wave. To combat this we apply window functions to the frame before the fft is applied. This is \\emph{short time fourier transform}.\n",
    "\n",
    "TODO: problems with accuracy for different frequencies when using for music and how CQT improves this with geometrically spaced frequencies instead of linearly spaced. Higher frequencies have larger bandwidths (bins?) and lower frequencies have smaller bandwidths. Smaller window functions for higher frequencies. (How are theese connected?)\n",
    "\n",
    "Different spacing for different frequency bins to not overlap as much?\n",
    "\n",
    "Compare STFT vs CQT sampling grids (where on the signal are we looking and applying the dot products basically)\n",
    "\n",
    "## CQT basics\n",
    "The reason for CQT is that having linearly spaced frequency bins does not work as well for music (and speech?) so we want to have them geometrically spaced instead since this apparently is more adapted to musical notes. The original paper defines the transform as\n",
    "\n",
    "\\begin{equation}\n",
    "    X(k, n) = \\sum^N_{m=0} x(m) a_k(n-m)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "     a_k(m) = g_k(m)e^{i2 \\pi m \\frac{f_k}{f_s}}\n",
    "\\end{equation}\n",
    "\n",
    "where $n$ are time indexes and $k$ are frequency indexes. Thus it transforms a real valued signal in time domain into time-frequency domain where the bin centers are geometrically spaced. Q is the ratio of center frequencies to bandwidths (widths of the frequency bins) and is in the basic settings, constant.\n",
    "\n",
    "TODO: problems with it, not invertible (why?) and slow\n",
    "\n",
    "## Improving CQT\n",
    "The same paper also suggested that since Eq. \\ref{eq:basic} is a convolution $[x \\ast a_k](n)$ it can be done as a multiplication in DFT domain instead. This is still bad complexity so the idea they introduced is that you don't have to evaluate this at every $n$ but instead it's enough to evaluate at every $n \\in 0, H_k, 2H_k, ...$, where $H_k$ is the hop size for frequency bin $k$. With this technique, the lack of an inverse is still a problem.\n",
    "\n",
    "## Windowing in fourier space\n",
    "wat\n",
    "\n",
    "## \"Discussions\"\n",
    "First understandings:\n",
    "\n",
    "Choose number of frequency bins and lowest frequency $f_0$. The bin centers are then computed as a geometric series based on first one\n",
    "\n",
    "For some signal $x(n)$ in time domain, we compute the CQT representation $X(k, n)$ for each frequency bin center $k$.\n",
    "\n",
    "For every frequency we have a $m$ centered window function $g_k(m)$ that acts on a part of the signal around $m$. The size of the window is inversely proportional to frequency $k$, ie high frequency $\\rightarrow$ small window.\n",
    "\n",
    "One Q per frequency bin $k$?? Two variants, either constant or not\n",
    "\n",
    "\n",
    "The equation at the top of this section is a convolution between $x$ and $a$ which can be done as multiplication in DFT domain instead.\n",
    "\n",
    "Then they talk about reducing the complexity of this by subsampling (not looking at all values basically) in the time domain. This can be done without losing any information by considering the \\emph{analysis hop size} which depends on the frequency $k$. They then do some mapping operation to mimic the subsampling in time domain in the frequency domain instead.\n",
    "\n",
    "But this is still not the same as the first equation since we lose some phase information?\n",
    "\n",
    "What makes it not invertible in its basic sense?\n",
    "\n",
    "Painless/non-painless case??\n",
    "\n",
    "TODO: What about these dual frames?\n",
    "\n",
    "Synthesis atoms = the windowed sample points (\"frames\"?) of signal???\n",
    "\n",
    "In the naive case, why would we calculate the cq coefficients at all positions n in the input signal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
